"""Check what models are available locally"""
from transformers import AutoModel
import os
import glob

cache_dir = os.path.expanduser('~/.cache/huggingface/hub')
print(f'\nğŸ“¦ HuggingFace Cache: {cache_dir}\n')

if os.path.exists(cache_dir):
    models = glob.glob(os.path.join(cache_dir, 'models--*'))
    print(f'Cached models: {len(models)}\n')
    for m in models[:15]:
        model_name = os.path.basename(m).replace("models--", "").replace("--", "/")
        print(f'  âœ… {model_name}')
else:
    print('âš ï¸  No cache found - models will download on first use')

print('\n' + '='*60)
print('ğŸ’¡ Models available for training:')
print('='*60)
print('âœ… distilbert-base-uncased (250MB)')
print('âœ… bert-base-uncased (440MB)')
print('âœ… roberta-base (500MB)')
print('\nâš ï¸  Custom models (may not exist):')
print('â“ mental/mental-bert-base-uncased')
print('â“ mental/mental-roberta-base')
print('\nğŸ’¡ Recommendation: Use standard models (distilbert, bert, roberta)')
