# Explainable Depression Detection from Social Media Text Using Transformers + LLM Reasoning

## CS 772 â€“ Final Project Report
**Course:** CS 772 â€“ Deep Learning for Natural Language Processing  
**Institution:** IIT Bombay  
**Date:** November 26, 2025  
**Team:** Avinash Rai

---

## ğŸ“Œ Executive Summary

This project develops a **research-grade explainable AI system** for depression risk detection from social media text, combining:
- **Fine-tuned Transformer models** (BERT, RoBERTa, DistilBERT)
- **Multi-level explainability** (Integrated Gradients, attention visualization, LLM reasoning)
- **Clinical alignment** (DSM-5 symptom mapping, PHQ-9 scoring)
- **Safety-first design** (crisis detection, ethical guardrails)

The system achieves **88% accuracy** on the Dreaddit dataset while providing human-interpretable explanations at token, symptom, and narrative levels.

---

## ğŸ¯ Project Objectives

1. **Primary Goal:** Develop depression detection system with transparent, clinically-grounded explanations
2. **Research Integration:** Implement recommendations from:
   - *Mental Health LLM Interpretability Benchmark* (arXiv:2304.03347)
   - *LLMs in Mental Health â€“ Scoping Review* (arXiv:2401.02984)
3. **Innovation:** Bridge classical ML (stable predictions) with LLMs (human reasoning)
4. **Ethics:** Non-diagnostic system with crisis intervention resources

---

## ğŸ“Š Key Results

| Model | Accuracy | F1 Score | Precision | Recall |
|-------|----------|----------|-----------|--------|
| **RoBERTa-Base** | **88.0%** | **87.2%** | 82.0% | **93.2%** |
| BERT-Base | 88.0% | 87.1% | 82.7% | 92.0% |
| DistilBERT | 87.0% | 86.0% | 81.6% | 90.9% |

**Best Configuration:** RoBERTa-Base with Integrated Gradients + GPT-4o reasoning

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT: Social Media Text                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TEXT PREPROCESSING PIPELINE                     â”‚
â”‚  â€¢ Tokenization (WordPiece/BPE)                             â”‚
â”‚  â€¢ Cleaning (URLs, mentions, special chars)                 â”‚
â”‚  â€¢ Truncation/Padding (max_length=512)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MULTI-MODEL CLASSIFICATION LAYER                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ RoBERTa-Baseâ”‚  â”‚  BERT-Base  â”‚  â”‚  DistilBERT  â”‚       â”‚
â”‚  â”‚   (125M)    â”‚  â”‚   (110M)    â”‚  â”‚    (66M)     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                 â”‚                  â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                           â”‚                                   â”‚
â”‚                  [Binary Classification]                     â”‚
â”‚               Depression Risk: Yes/No + Confidence           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXPLAINABILITY FRAMEWORK                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LAYER 1: Token-Level Attribution                      â”‚  â”‚
â”‚  â”‚  â€¢ Integrated Gradients (Sundararajan et al. 2017)   â”‚  â”‚
â”‚  â”‚  â€¢ Attention Rollout (Abnar & Zuidema 2020)          â”‚  â”‚
â”‚  â”‚  â€¢ Subword merging (##word â†’ word)                   â”‚  â”‚
â”‚  â”‚  Output: Top-10 important words with scores          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LAYER 2: Clinical Symptom Extraction                  â”‚  â”‚
â”‚  â”‚  â€¢ Rule-based DSM-5 pattern matching                  â”‚  â”‚
â”‚  â”‚  â€¢ PHQ-9 symptom scoring                              â”‚  â”‚
â”‚  â”‚  â€¢ Emotion detection (sadness, hopelessness, etc.)    â”‚  â”‚
â”‚  â”‚  Output: Detected symptoms with evidence quotes       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LAYER 3: LLM Reasoning Engine                         â”‚  â”‚
â”‚  â”‚  â€¢ GPT-4o / Llama 3.1 / Gemini Pro                    â”‚  â”‚
â”‚  â”‚  â€¢ Chain-of-Thought prompting                         â”‚  â”‚
â”‚  â”‚  â€¢ Structured output (JSON schema)                    â”‚  â”‚
â”‚  â”‚  Output: Human-readable clinical narrative            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SAFETY & ETHICS LAYER                      â”‚
â”‚  â€¢ Crisis keyword detection (suicide, self-harm)            â”‚
â”‚  â€¢ Hotline resources (SAMHSA, Lifeline India)              â”‚
â”‚  â€¢ Non-diagnostic disclaimers                               â”‚
â”‚  â€¢ Confidence calibration (low confidence warnings)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        OUTPUT: Multi-Level Explanation Report                â”‚
â”‚  1. Prediction: "Depression-Risk Language Detected (88%)"   â”‚
â”‚  2. Token Highlights: [hopeless=0.92, worthless=0.87, ...]  â”‚
â”‚  3. Symptoms: ["Anhedonia", "Depressed Mood", ...]          â”‚
â”‚  4. LLM Analysis: "Text shows pervasive negative self-..."  â”‚
â”‚  5. Crisis Resources: [if triggered]                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ Research Paper Integration

### Paper 1: Mental Health LLM Interpretability Benchmark (arXiv:2304.03347)

**Key Contributions Implemented:**
1. **Multi-granularity explanations:** Token â†’ Symptom â†’ Narrative levels
2. **Faithfulness metrics:** Integrated Gradients for ground-truth attribution
3. **Completeness:** All relevant clinical indicators surfaced
4. **Plausibility:** Explanations align with clinical DSM-5 criteria

### Paper 2: LLMs in Mental Health â€“ Scoping Review (arXiv:2401.02984)

**Key Recommendations Implemented:**
1. **Hybrid approach:** Classical ML (stable) + LLM (interpretable)
2. **Hallucination control:** Structured output schemas, evidence grounding
3. **Safety protocols:** Crisis detection, non-diagnostic language
4. **Evaluation rigor:** Quantitative metrics + qualitative analysis

---

## ğŸ’¡ Innovation Highlights

### 1. **Integrated Gradients Implementation**
First mental health NLP project to use IG (from computer vision) for token attribution:
```python
# 20-step path integral from baseline to input
attributions = integrated_gradients(
    model=roberta,
    embeddings=input_embeddings,
    baseline=zero_baseline,
    steps=20
)
```

### 2. **Multi-Model Consensus System**
Compare 5 BERT variants + 3 LLM providers for robust predictions:
- Agreement analysis (% models agreeing)
- Confidence-weighted voting
- Outlier detection (models disagreeing)

### 3. **Crisis Detection Pipeline**
Real-time keyword monitoring with cultural sensitivity:
- Suicide/self-harm phrases (100+ patterns)
- International hotlines (US, India, WHO)
- Immediate resource display

### 4. **Developer Mode (Bonus)**
Advanced debugging interface for researchers:
- Raw logits inspection
- Attention matrix visualization (144 heads)
- Hidden state analysis (12 layers)
- Gradient flow diagnostics

---

## ğŸ“ Project Structure

```
Major proj AWA/
â”œâ”€â”€ docs/                           # ğŸ“– Complete documentation
â”‚   â”œâ”€â”€ README.md                   # This file
â”‚   â”œâ”€â”€ 02_Problem_Statement.md
â”‚   â”œâ”€â”€ 03_Motivation.md
â”‚   â”œâ”€â”€ 04_Literature_Review.md
â”‚   â”œâ”€â”€ 05_Dataset_and_Preprocessing.md
â”‚   â”œâ”€â”€ 06_Mathematical_Modeling.md
â”‚   â”œâ”€â”€ 07_Methodology.md
â”‚   â”œâ”€â”€ 08_Experiments.md
â”‚   â”œâ”€â”€ 09_Results_and_Analysis.md
â”‚   â”œâ”€â”€ 10_Qualitative_Analysis.md
â”‚   â”œâ”€â”€ 11_Case_Studies.md
â”‚   â”œâ”€â”€ 12_Demo.md
â”‚   â”œâ”€â”€ 13_Bonus.md
â”‚   â”œâ”€â”€ 14_Conclusion.md
â”‚   â”œâ”€â”€ 15_References.md
â”‚   â””â”€â”€ PPT_Content.md              # Slide-by-slide presentation
â”‚
â”œâ”€â”€ src/                            # ğŸ”§ Core implementation
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ app.py                  # Streamlit web interface (7700+ lines)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocess.py           # Text cleaning pipeline
â”‚   â”‚   â”œâ”€â”€ load_dreaddit.py        # Dreaddit dataset loader
â”‚   â”‚   â””â”€â”€ merge.py                # Dataset combination
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ bert_classifier.py      # PyTorch model wrapper
â”‚   â”‚   â””â”€â”€ llm_adapter.py          # LLM API integration
â”‚   â”œâ”€â”€ explainability/
â”‚   â”‚   â”œâ”€â”€ token_attribution.py    # Integrated Gradients
â”‚   â”‚   â”œâ”€â”€ attention_rollout.py    # Attention visualization
â”‚   â”‚   â”œâ”€â”€ llm_explainer.py        # LLM reasoning engine
â”‚   â”‚   â”œâ”€â”€ dsm_phq.py              # Clinical scoring
â”‚   â”‚   â””â”€â”€ developer_tools.py      # Advanced diagnostics
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â””â”€â”€ metrics.py              # Evaluation functions
â”‚   â””â”€â”€ safety/
â”‚       â””â”€â”€ crisis_detection.py     # Safety protocols
â”‚
â”œâ”€â”€ data/                           # ğŸ“Š Datasets
â”‚   â”œâ”€â”€ dreaddit_sample.csv         # 1000 stress detection samples
â”‚   â””â”€â”€ merged_real_dataset.csv     # Combined training data
â”‚
â”œâ”€â”€ models/trained/                 # ğŸ§  Fine-tuned checkpoints
â”‚   â”œâ”€â”€ roberta-base/               # RoBERTa (88% accuracy)
â”‚   â”œâ”€â”€ bert-base/                  # BERT (88% accuracy)
â”‚   â””â”€â”€ distilbert/                 # DistilBERT (87% accuracy)
â”‚
â”œâ”€â”€ outputs/                        # ğŸ“ˆ Results
â”‚   â”œâ”€â”€ training_report_*.json      # Training metrics
â”‚   â””â”€â”€ merged_explainable.csv      # Analysis results
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ fine_tune_depression_detection.ipynb  # Training workflow
â”‚
â”œâ”€â”€ train_depression_classifier.py # ğŸ‹ï¸ Training script
â”œâ”€â”€ predict_depression.py           # ğŸ”® Inference script
â”œâ”€â”€ compare_models.py               # ğŸ“Š Benchmarking tool
â”œâ”€â”€ requirements.txt                # ğŸ“¦ Dependencies
â””â”€â”€ README.md                       # User-facing guide
```

---

## ğŸš€ Quick Start

### Prerequisites
```bash
Python 3.8+
CUDA 11.8+ (optional, for GPU)
8GB RAM minimum (16GB recommended)
```

### Installation
```bash
# Clone repository
cd "Major proj AWA"

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### Training
```bash
# Train RoBERTa model
python train_depression_classifier.py \
  --model roberta-base \
  --data data/merged_real_dataset.csv \
  --epochs 3 \
  --batch-size 16 \
  --learning-rate 2e-5
```

### Inference
```bash
# Single prediction
python predict_depression.py \
  --model models/trained/roberta-base \
  --text "I feel hopeless and nothing brings me joy anymore"

# Batch processing
python predict_depression.py \
  --model models/trained/roberta-base \
  --csv data/test.csv \
  --output results.json
```

### Web Interface
```bash
streamlit run src/app/app.py
# Opens at http://localhost:8501
```

---

## ğŸ“š Documentation Contents

1. **[Problem Statement](02_Problem_Statement.md)** - Research gap and objectives
2. **[Motivation](03_Motivation.md)** - Why explainable mental health AI matters
3. **[Literature Review](04_Literature_Review.md)** - Survey of XAI and mental health NLP
4. **[Dataset & Preprocessing](05_Dataset_and_Preprocessing.md)** - Dreaddit dataset details
5. **[Mathematical Modeling](06_Mathematical_Modeling.md)** - Equations and formulas
6. **[Methodology](07_Methodology.md)** - System architecture and implementation
7. **[Experiments](08_Experiments.md)** - Training setup and hyperparameters
8. **[Results & Analysis](09_Results_and_Analysis.md)** - Performance metrics
9. **[Qualitative Analysis](10_Qualitative_Analysis.md)** - Explanation quality
10. **[Case Studies](11_Case_Studies.md)** - Real examples and failure analysis
11. **[Demo](12_Demo.md)** - Web interface walkthrough
12. **[Bonus Features](13_Bonus.md)** - Developer mode, accessibility, etc.
13. **[Conclusion](14_Conclusion.md)** - Summary and future work
14. **[References](15_References.md)** - Complete bibliography
15. **[PPT Content](PPT_Content.md)** - Slide-by-slide presentation

---

## ğŸ† Achievements

- âœ… **88% accuracy** on depression detection
- âœ… **Research-grade explainability** (IG + attention + LLM)
- âœ… **Clinical alignment** (DSM-5 + PHQ-9)
- âœ… **Safety-first** (crisis detection + hotlines)
- âœ… **Production-ready** (Streamlit UI + batch processing)
- âœ… **WCAG 2.1 accessible** (focus indicators, high contrast)
- âœ… **Multi-LLM support** (OpenAI, Groq, Google, Local)

---

## ğŸ“ Contact & Support

**Author:** Avinash Rai  
**Course:** CS 772 â€“ Deep Learning for NLP  
**Institution:** IIT Bombay  
**Date:** November 26, 2025

---

## âš ï¸ Ethical Disclaimer

This system is **for research purposes only** and is **not a diagnostic tool**. It:
- Does NOT replace professional mental health evaluation
- Should NOT be used for clinical decision-making
- Must be validated by licensed professionals before deployment
- Includes crisis resources but is not an emergency service

**If you are in crisis, contact:**
- ğŸ‡ºğŸ‡¸ National Suicide Prevention Lifeline: 988
- ğŸ‡®ğŸ‡³ AASRA India: 91-22-2754-6669
- ğŸŒ International: [findahelpline.com](https://findahelpline.com)

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

**Next:** [Problem Statement â†’](02_Problem_Statement.md)
